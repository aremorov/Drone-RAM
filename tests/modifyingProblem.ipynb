{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bbbcf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from modules import Retina\n",
    "from utils import array2img, img2array\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "\n",
    "import model\n",
    "import utils\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import data_loader\n",
    "from config import get_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af04ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model (code from load_checkpoint function in trainer.py):\n",
    "\n",
    "config, unparsed = get_config()\n",
    "\n",
    "\n",
    "filename = \"../ckpt/ram_6_1x1_1_model_best.pth.tar\"\n",
    "\n",
    "ckpt = torch.load(filename) #model\n",
    "\n",
    "# build RAM model\n",
    "config, unparsed = get_config()\n",
    "\n",
    "ram0 = model.RecurrentAttention(\n",
    "    1,\n",
    "    config.num_patches,\n",
    "    config.glimpse_scale,\n",
    "    1,\n",
    "    config.loc_hidden,\n",
    "    config.glimpse_hidden,\n",
    "    config.std,\n",
    "    config.hidden_size,\n",
    "    10,\n",
    ")\n",
    "\n",
    "ram0.load_state_dict(ckpt[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3b27c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model data:\n",
      " patch size: 1\n",
      " num_patches: 1\n",
      " glimpse_scale: 1\n",
      " num_channels: 1\n",
      " loc_hidden: 128\n",
      " glimpse_hidden: 128\n",
      " std: 0.05\n",
      " hidden_size: 256\n",
      " num_classes: 10\n"
     ]
    }
   ],
   "source": [
    "print(\" Model data:\\n patch size: \" + str(config.patch_size) + \n",
    "    \"\\n num_patches: \" + str(config.num_patches)+\n",
    "    \"\\n glimpse_scale: \" + str(config.glimpse_scale)+\n",
    "    \"\\n num_channels: \" + str(1)+\n",
    "    \"\\n loc_hidden: \" + str(config.loc_hidden)+\n",
    "    \"\\n glimpse_hidden: \" + str(config.glimpse_hidden)+\n",
    "    \"\\n std: \" + str(config.std)+\n",
    "    \"\\n hidden_size: \" + str(config.hidden_size)+\n",
    "    \"\\n num_classes: \" + str(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aeddb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    h_t = torch.zeros(\n",
    "        1,\n",
    "        config.hidden_size,\n",
    "        dtype=torch.float,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    l_t = torch.FloatTensor(\n",
    "        1, 2).uniform_(-1, 1)\n",
    "    l_t.requires_grad = True\n",
    "\n",
    "    return h_t, l_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413b8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize((0.1307,), (0.3081,))\n",
    "trans = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "dataset = datasets.MNIST(\"../data\", train=False, download=True, transform=trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6de8114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 8, actual: 6\n"
     ]
    }
   ],
   "source": [
    "mnistImage, label = dataset[11]\n",
    "mnistImage = mnistImage.unsqueeze(1)\n",
    "\n",
    "#do 10 glimpses\n",
    "h_t, l_t = reset()\n",
    "\n",
    "loc_list = []\n",
    "for t in range(5):\n",
    "    # forward pass through model\n",
    "    h_t, l_t, b_t, p = ram0(mnistImage, l_t, h_t)\n",
    "    loc_list.append(l_t)\n",
    "\n",
    "# last iteration\n",
    "h_t, l_t, b_t, log_probas, p = ram0(mnistImage, l_t, h_t, last=True)\n",
    "\n",
    "pred = log_probas.data.max(1, keepdim=True)[1][0][0].item()\n",
    "print(\"Prediction: \" + str(pred) + \", actual: \" + str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02b7a3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABLCAYAAABOfV0NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAABdElEQVR4nO3asW3DMABFQTLwCqmz/1juvQO9AAupiJ8B3tUsiA/pwTA011oDgM/7qS8AcCoBBogIMEBEgAEiAgwQEWCAyOPO4TnnEd+srbXm1bOnbDLGeK21fq8ctMneKbt4f7a2z4pfwFz1rC/whWzCVdtnRYABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaIPG6ef40xnv9xkS/yd/P8CZuMcW8Xm+ydsItN9ra7zLXWpy8CwPAXBEBGgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEDkDWdOKdKWCn5FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_patches = config.num_patches\n",
    "scale = config.glimpse_scale\n",
    "patch_size = config.patch_size\n",
    "\n",
    "glimpses = []\n",
    "for loc in loc_list:\n",
    "    ret = Retina(g=patch_size, k=num_patches, s=scale)\n",
    "    glimpse = ret.foveate(mnistImage, loc).data.numpy()\n",
    "    glimpse = np.reshape(glimpse, [1, num_patches, 1, patch_size, patch_size])\n",
    "    glimpse = np.transpose(glimpse, [0, 1, 3, 4, 2])\n",
    "    glimpses.append(glimpse)\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(glimpses))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    axs[i].imshow(glimpses[i][0][0], cmap=\"gray\")\n",
    "    axs[i].get_xaxis().set_visible(False)\n",
    "    axs[i].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "608eeb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc18d6b6580>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOIUlEQVR4nO3dX6wc9XnG8ecBEgTEkk0RtgFT0gBSK6T6WAiQDBUlJHJtJJyL1OGioipwEAp/ValAMATJVEK04DuQDhjhokAUCZyYgEoAo9LacoRt8ceOAVMEwfGRzZ8LHHGBMW8vzjg9mLO/OezO7qz9fj/S0e7Oe2bm9dqPZ3Z/u/NzRAjA4e+IthsAMBiEHUiCsANJEHYgCcIOJHHUIHdmm7f+gT6LCE+1vKcju+1Ftt+0/bbtW3rZFoD+crfj7LaPlPSWpO9J2inpZUmXRcTvCutwZAf6rB9H9nMkvR0R70TEZ5J+LunSHrYHoI96CfvJkt6f9HhntexLbI/a3mR7Uw/7AtCjXt6gm+pU4Sun6RExJmlM4jQeaFMvR/adkuZNenyKpF29tQOgX3oJ+8uSzrD9bdvflPQjSWubaQtA07o+jY+Iz21fK+lZSUdKejgitjXWGYBGdT301tXOeM0O9F1fPlQD4NBB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEgO9lDS6c/TRRxfr69ev71gbGRkprvvUU08V60uXLi3WcejgyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOPgTqxtFXrlxZrM+fP79jre7qwZs3by7WcfjgyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOPgSuv/76Yn10dLRYX7duXcfaHXfcUVx348aNxToOHz2F3fa7kvZK2i/p84g4u4mmADSviSP730bEhw1sB0Af8ZodSKLXsIek39jebHvKF5a2R21vsr2px30B6EGvp/ELI2KX7RMlPWf7jYh4afIvRMSYpDFJsl3+VgaAvunpyB4Ru6rbPZLWSDqniaYANK/rsNs+zvaMA/clfV/S1qYaA9CsXk7jZ0taY/vAdh6LiP9spKtk5syZ09P6zz//fMca4+g4oOuwR8Q7kv66wV4A9BFDb0AShB1IgrADSRB2IAnCDiTBV1yHwIwZM4r1ffv2FeuloTfgAI7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5CE66b0bXRnSa9Uc9JJJxXr77//frG+YcOGYv2CCy742j3h8BURnmo5R3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILvsw/A8uXL227hkHTeeecV6/Pmzet626+++mqx/tZbb3W97WHFkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfQCWLFnS0/qrVq1qqJPBe+CBBzrW6p6XWbNmFevHHHNMVz1J0ieffFKsr1y5slhfsWJF1/tuS+2R3fbDtvfY3jpp2fG2n7O9o7ot/60AaN10TuMfkbTooGW3SHohIs6Q9EL1GMAQqw17RLwk6eODFl8qaXV1f7Wkpc22BaBp3b5mnx0R45IUEeO2T+z0i7ZHJY12uR8ADen7G3QRMSZpTMp7wUlgGHQ79Lbb9lxJqm73NNcSgH7oNuxrJV1e3b9c0q+aaQdAv9ReN97245IulHSCpN2Sfirpl5J+IelUSb+X9MOIOPhNvKm2dViexh977LHF+o4dO4r1/fv3F+unnnrq1+5puo46qvxKbsGCBcX6mjVrivU5c+Z0rB1xRPlY88EHHxTr69evL9ZLvdc9pzt37izWzz///GL9vffeK9b7qdN142tfs0fEZR1K3+2pIwADxcdlgSQIO5AEYQeSIOxAEoQdSIKvuDbgyiuvLNZnz55drI+NjTXZzpfUTRc9Olr+JHOvl8HetWtXx9qjjz5aXPf+++8v1uuGx0rWrl1brC9evLhYnzt3brHe5tBbJxzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkbMDIy0tP6dV+B7UXdOPnVV19drNd9BXrdunXF+k033dSxtm3btuK6/dTP53xYcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ29A3XfG++3MM8/sWFu2bFlP237wwQeL9RtuuKFY/+yzz3raf1u2bNnSU30YcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ2/AjBkzinV7yhl0G3Pdddd1rM2cObO47mOPPVasX3PNNd20NPTq/s727dtXrB+Knx+oPbLbftj2HttbJy270/YfbL9S/ZSvqA+gddM5jX9E0qIplq+MiPnVzzPNtgWgabVhj4iXJH08gF4A9FEvb9Bda/u16jR/Vqdfsj1qe5PtTT3sC0CPug37A5K+I2m+pHFJ93b6xYgYi4izI+LsLvcFoAFdhT0idkfE/oj4QtKDks5pti0ATesq7LYnz1f7A0lbO/0ugOFQO85u+3FJF0o6wfZOST+VdKHt+ZJC0ruSyhcfP8zVXVu9rt6r0lzhdfuum2f8UFa6zsAVV1xRXPfJJ59sup3W1YY9Ii6bYvGqPvQCoI/4uCyQBGEHkiDsQBKEHUiCsANJ8BXXw0Bp2uWFCxcW162r33rrrcX62NhYsf7RRx8V6/1UGj779NNPi+vee2/HD4UesjiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLNPU+nrkm1/TbQ0lr1gwYLiumvXri3WV6xYUawvWjTVtUj/3yWXXNKxtnfv3q7XlaTly5cX6yMjIx1rd911V3HdjRs3FuuHIo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5CE+32Z4y/tzB7czgbo2WefLdYvvvjiYv2ZZ8rzYi5btqxYr/tudi/qxrq3b99erJemNr799tuL69Zd7rnuz33PPfd0rNV9fuBQFhFTzhHOkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcvQGnnHJKsf70008X62eddVaxvmHDhmL9vvvu61gbHx8vrltnyZIlxfpFF11UrJ977rkda/aUw8F/8uabbxbrt912W7G+Zs2aYv1w1fU4u+15tl+0vd32Nts3VMuPt/2c7R3V7aymmwbQnOmcxn8u6Z8j4i8lnSfpx7b/StItkl6IiDMkvVA9BjCkasMeEeMRsaW6v1fSdkknS7pU0urq11ZLWtqnHgE04Gtdg872aZJGJP1W0uyIGJcm/kOwfWKHdUYljfbYJ4AeTTvstr8l6QlJN0bEJ3VvrhwQEWOSxqptHJZv0AGHgmkNvdn+hiaC/rOIODA15m7bc6v6XEl7+tMigCbUDr154hC+WtLHEXHjpOX/JumjiLjb9i2Sjo+If6nZVsoje92lpl988cVi/fTTT2+ynS+pO0Pr59DsI488UqzffPPNxXqb00EPs05Db9M5jV8o6R8kvW77lWrZTyTdLekXtq+Q9HtJP2ygTwB9Uhv2iPgfSZ3++/9us+0A6Bc+LgskQdiBJAg7kARhB5Ig7EASfMV1CMycObNYr7uUdGkc/qqrriqu+9BDDxXrvf77WLVqVcfaG2+80dO2MTUuJQ0kR9iBJAg7kARhB5Ig7EAShB1IgrADSTDODhxmGGcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJGrDbnue7Rdtb7e9zfYN1fI7bf/B9ivVz+L+twugW7UXr7A9V9LciNhie4akzZKWSvp7SX+MiH+f9s64eAXQd50uXjGd+dnHJY1X9/fa3i7p5GbbA9BvX+s1u+3TJI1I+m216Frbr9l+2PasDuuM2t5ke1NvrQLoxbSvQWf7W5L+S9K/RsSTtmdL+lBSSFqhiVP9f6rZBqfxQJ91Oo2fVthtf0PSryU9GxH3TVE/TdKvI+Ksmu0QdqDPur7gpG1LWiVp++SgV2/cHfADSVt7bRJA/0zn3fjzJf23pNclfVEt/omkyyTN18Rp/LuSrq7ezCttiyM70Gc9ncY3hbAD/cd144HkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0nUXnCyYR9Kem/S4xOqZcNoWHsb1r4keutWk739eafCQL/P/pWd25si4uzWGigY1t6GtS+J3ro1qN44jQeSIOxAEm2Hfazl/ZcMa2/D2pdEb90aSG+tvmYHMDhtH9kBDAhhB5JoJey2F9l+0/bbtm9po4dObL9r+/VqGupW56er5tDbY3vrpGXH237O9o7qdso59lrqbSim8S5MM97qc9f29OcDf81u+0hJb0n6nqSdkl6WdFlE/G6gjXRg+11JZ0dE6x/AsP03kv4o6T8OTK1l+x5JH0fE3dV/lLMi4uYh6e1Ofc1pvPvUW6dpxv9RLT53TU5/3o02juznSHo7It6JiM8k/VzSpS30MfQi4iVJHx+0+FJJq6v7qzXxj2XgOvQ2FCJiPCK2VPf3SjowzXirz12hr4FoI+wnS3p/0uOdGq753kPSb2xvtj3adjNTmH1gmq3q9sSW+zlY7TTeg3TQNOND89x1M/15r9oI+1RT0wzT+N/CiFgg6e8k/bg6XcX0PCDpO5qYA3Bc0r1tNlNNM/6EpBsj4pM2e5lsir4G8ry1EfadkuZNenyKpF0t9DGliNhV3e6RtEYTLzuGye4DM+hWt3ta7udPImJ3ROyPiC8kPagWn7tqmvEnJP0sIp6sFrf+3E3V16CetzbC/rKkM2x/2/Y3Jf1I0toW+vgK28dVb5zI9nGSvq/hm4p6raTLq/uXS/pVi718ybBM491pmnG1/Ny1Pv15RAz8R9JiTbwj/7+Sbmujhw59/YWkV6ufbW33JulxTZzW7dPEGdEVkv5M0guSdlS3xw9Rb49qYmrv1zQRrLkt9Xa+Jl4avibplepncdvPXaGvgTxvfFwWSIJP0AFJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEv8HCSFtEU2Av7kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnistImage[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2ca3cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistImage[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a464174",
   "metadata": {},
   "source": [
    "# Make intensity function at location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "655449f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return form: tensor([[[-0.4242]]])\n",
    "\n",
    "#current extract patch code:\n",
    "\n",
    "      \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        start = self.denormalize(H, l)\n",
    "        end = start + size\n",
    "        # pad with zeros\n",
    "        # x = F.pad(x, (size // 2, size // 2, size // 2, size // 2))\n",
    "        x = F.pad(x, (1, 1, 1, 1))\n",
    "        print(x.shape)\n",
    "\n",
    "        # loop through mini-batch and extract patches\n",
    "        patch = []\n",
    "        for i in range(B):\n",
    "            print(x[i, :, start[i, 1]: end[i, 1], start[i, 0]: end[i, 0]])\n",
    "\n",
    "            patch.append(\n",
    "                x[i, :, start[i, 1]: end[i, 1], start[i, 0]: end[i, 0]])\n",
    "        return torch.stack(patch)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b30ed7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 6])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing denormalize function\n",
    "\n",
    "\"\"\"Convert coordinates in the range [-1, 1] to\n",
    "        coordinates in the range [0, T] where `T` is\n",
    "        the size of the image.\n",
    "        \n",
    "        return (0.5 * ((coords + 1.0) * T)).long()\n",
    "\"\"\"\n",
    "H1 = 15\n",
    "loc1 = torch.tensor([0.1, -0.09])\n",
    "Retina.denormalize(_, H1, loc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5895037f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(4.3).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a3bec74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointCharge(r, q):\n",
    "    return -q/r**2\n",
    "\n",
    "def intensity(loc, img): #loc is tensor([index1, index2]), img is tensor with shape: (1,H,W), generally H=W\n",
    "    totalCharge = 0\n",
    "    nRows, nColumns = img.shape\n",
    "    xLoc = loc[1].item()\n",
    "    yLoc = loc[0].item()\n",
    "    for yi in range(nRows):\n",
    "        for xi in range(nColumns):\n",
    "            r2 = ((xLoc - xi) ** 2 + (yLoc - yi) ** 2)\n",
    "            if(r2 != 0):\n",
    "                pointCharge = img[yi,xi]/r2\n",
    "                totalCharge += pointCharge\n",
    "    return totalCharge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fa452afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = np.arange(25).reshape(5,5)\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "81460711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0,4])[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dc9dc669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.6773)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc1 = torch.tensor([1, 6])\n",
    "\n",
    "intensity(loc1, mnistImage[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0b18b9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testImg1 = np.zeros([5,5])\n",
    "testImg1[0,0] = 1\n",
    "testImg1[2,2] = 0.1\n",
    "testLoc1 = torch.tensor([2,2])\n",
    "intensity(testLoc1, testImg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "30919444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fc1a9a42d60>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testImg1, cmap=\"gray\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdebc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
