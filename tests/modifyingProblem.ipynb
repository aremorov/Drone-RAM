{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c7bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from modules import Retina\n",
    "from utils import array2img, img2array\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "\n",
    "import model\n",
    "import utils\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import data_loader\n",
    "from config import get_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3946ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model (code from load_checkpoint function in trainer.py):\n",
    "\n",
    "config, unparsed = get_config()\n",
    "\n",
    "\n",
    "filename = \"../ckpt/ram_6_1x1_1_model_best.pth.tar\"\n",
    "\n",
    "ckpt = torch.load(filename) #model\n",
    "\n",
    "# build RAM model\n",
    "config, unparsed = get_config()\n",
    "\n",
    "ram0 = model.RecurrentAttention(\n",
    "    1,\n",
    "    config.num_patches,\n",
    "    config.glimpse_scale,\n",
    "    1,\n",
    "    config.loc_hidden,\n",
    "    config.glimpse_hidden,\n",
    "    config.std,\n",
    "    config.hidden_size,\n",
    "    10,\n",
    ")\n",
    "\n",
    "ram0.load_state_dict(ckpt[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69e577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model data:\n",
      " patch size: 1\n",
      " num_patches: 1\n",
      " glimpse_scale: 1\n",
      " num_channels: 1\n",
      " loc_hidden: 128\n",
      " glimpse_hidden: 128\n",
      " std: 0.05\n",
      " hidden_size: 256\n",
      " num_classes: 10\n"
     ]
    }
   ],
   "source": [
    "print(\" Model data:\\n patch size: \" + str(config.patch_size) + \n",
    "    \"\\n num_patches: \" + str(config.num_patches)+\n",
    "    \"\\n glimpse_scale: \" + str(config.glimpse_scale)+\n",
    "    \"\\n num_channels: \" + str(1)+\n",
    "    \"\\n loc_hidden: \" + str(config.loc_hidden)+\n",
    "    \"\\n glimpse_hidden: \" + str(config.glimpse_hidden)+\n",
    "    \"\\n std: \" + str(config.std)+\n",
    "    \"\\n hidden_size: \" + str(config.hidden_size)+\n",
    "    \"\\n num_classes: \" + str(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "677bc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    h_t = torch.zeros(\n",
    "        1,\n",
    "        config.hidden_size,\n",
    "        dtype=torch.float,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    l_t = torch.FloatTensor(\n",
    "        1, 2).uniform_(-1, 1)\n",
    "    l_t.requires_grad = True\n",
    "\n",
    "    return h_t, l_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31ec340",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize((0.1307,), (0.3081,))\n",
    "trans = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "dataset = datasets.MNIST(\"../data\", train=False, download=True, transform=trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52a2f1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 8, actual: 6\n"
     ]
    }
   ],
   "source": [
    "mnistImage, label = dataset[11]\n",
    "mnistImage = mnistImage.unsqueeze(1)\n",
    "\n",
    "#do 10 glimpses\n",
    "h_t, l_t = reset()\n",
    "\n",
    "loc_list = []\n",
    "for t in range(5):\n",
    "    # forward pass through model\n",
    "    h_t, l_t, b_t, p = ram0(mnistImage, l_t, h_t)\n",
    "    loc_list.append(l_t)\n",
    "\n",
    "# last iteration\n",
    "h_t, l_t, b_t, log_probas, p = ram0(mnistImage, l_t, h_t, last=True)\n",
    "\n",
    "pred = log_probas.data.max(1, keepdim=True)[1][0][0].item()\n",
    "print(\"Prediction: \" + str(pred) + \", actual: \" + str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4604d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABLCAYAAABOfV0NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAABdElEQVR4nO3asW3DMABFQTLwCqmz/1juvQO9AAupiJ8B3tUsiA/pwTA011oDgM/7qS8AcCoBBogIMEBEgAEiAgwQEWCAyOPO4TnnEd+srbXm1bOnbDLGeK21fq8ctMneKbt4f7a2z4pfwFz1rC/whWzCVdtnRYABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaIPG6ef40xnv9xkS/yd/P8CZuMcW8Xm+ydsItN9ra7zLXWpy8CwPAXBEBGgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEDkDWdOKdKWCn5FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_patches = config.num_patches\n",
    "scale = config.glimpse_scale\n",
    "patch_size = config.patch_size\n",
    "\n",
    "glimpses = []\n",
    "for loc in loc_list:\n",
    "    ret = Retina(g=patch_size, k=num_patches, s=scale)\n",
    "    glimpse = ret.foveate(mnistImage, loc).data.numpy()\n",
    "    glimpse = np.reshape(glimpse, [1, num_patches, 1, patch_size, patch_size])\n",
    "    glimpse = np.transpose(glimpse, [0, 1, 3, 4, 2])\n",
    "    glimpses.append(glimpse)\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(glimpses))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    axs[i].imshow(glimpses[i][0][0], cmap=\"gray\")\n",
    "    axs[i].get_xaxis().set_visible(False)\n",
    "    axs[i].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b17abad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc18d6b6580>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnistImage[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769bc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
